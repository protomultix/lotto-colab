{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üìò Anleitung: Starten des Notebooks\n",
        "\n",
        "Dieses Notebook wird von GitHub geladen. Um die Analyse zu starten, folgen Sie bitte diesen Schritten:\n",
        "\n",
        "1. **Umgebung vorbereiten:** Gehen Sie oben im Men√º auf **Laufzeit** (Runtime) ‚Üí **Alle ausf√ºhren** (Run all).\n",
        "2. **Warnung best√§tigen:** Wenn das Fenster *\"Warnung: Dieses Notebook wurde nicht von Google erstellt\"* erscheint, klicken Sie auf **‚ÄûTrotzdem ausf√ºhren‚Äú**.\n",
        "3. **Berechnung starten:** Sobald das Bedienfeld erscheint, klicken Sie unten auf die gr√ºne Schaltfl√§che **‚ñ∂ Ausf√ºhren**.\n",
        "\n",
        "---\n",
        "*Die Warnung ist eine Google-Sicherheitsma√ünahme f√ºr GitHub-Dateien. Die gr√ºne Schaltfl√§che trainiert das KI-Modell und sendet die Prognosen an die App.*"
      ],
      "metadata": {
        "id": "ZIA0FXgkgnvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title üéÆ START CONTROL PANEL\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# UI definieren\n",
        "style = \"\"\"<style>.lotto-box{background:#f8f9fa;padding:15px;border-radius:10px;border:1px solid #ddd;}.lbl{font-weight:bold;font-size:16px;margin-bottom:10px;display:block;}</style>\"\"\"\n",
        "display(HTML(style))\n",
        "\n",
        "lbl = widgets.HTML('<span class=\"lbl\">üé≤ LOTTO 6aus49 KI-Generator</span>')\n",
        "txt_uid = widgets.Text(placeholder=\"User ID (Auto)\", description=\"üÜî ID:\", layout=widgets.Layout(width='200px'))\n",
        "btn_go = widgets.Button(description=\"Start Pipeline\", button_style='success', icon='rocket', layout=widgets.Layout(width='150px'))\n",
        "out_log = widgets.Output(layout={'border':'1px solid #ccc','height':'150px','overflow':'auto','margin_top':'10px'})\n",
        "progress = widgets.IntProgress(value=0, max=100, layout=widgets.Layout(width='100%'))\n",
        "\n",
        "# Logik-Verbindung (\"Bridge\" variables for next cell)\n",
        "global_ui = {\n",
        "    \"btn\": btn_go, \"txt\": txt_uid, \"log\": out_log, \"bar\": progress\n",
        "}\n",
        "\n",
        "def on_click_wrapper(b):\n",
        "    # Diese Funktion wird sp√§ter von Zelle 2 √ºberschrieben/genutzt\n",
        "    if 'run_lotto_logic' in globals():\n",
        "        globals()['run_lotto_logic'](global_ui)\n",
        "    else:\n",
        "        with out_log: print(\"‚ö†Ô∏è Bitte Zelle 2 (Code) auch ausf√ºhren!\")\n",
        "\n",
        "btn_go.on_click(on_click_wrapper)\n",
        "\n",
        "# Anzeigen\n",
        "display(widgets.VBox([lbl, widgets.HBox([txt_uid, btn_go]), progress, out_log])) # .add_class('lotto-box')\n",
        "\n",
        "# Auto-ID Check (JS Hack)\n",
        "from google.colab import output\n",
        "js = \"\"\"(function(){\n",
        "  var h=window.location.hash.slice(1);\n",
        "  var p={}; h.split('&').forEach(function(v){var i=v.split('=');p[i[0]]=i[1];});\n",
        "  return p.userId || \"\";\n",
        "})();\"\"\"\n",
        "try:\n",
        "    uid_found = output.eval_js(js)\n",
        "    if uid_found: txt_uid.value = str(uid_found)\n",
        "except: pass"
      ],
      "metadata": {
        "id": "20ACDMrZi0o_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ‚öôÔ∏è CORE SYSTEM (Original Power Model)\n",
        "import time, requests, json, zipfile, io, os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "BACKEND = \"https://apilotto.euroceiling39.ru\"\n",
        "\n",
        "# --- ORIIGNAL POWER MODEL ---\n",
        "def create_model(input_shape, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    # Layer 1\n",
        "    model.add(Bidirectional(LSTM(240, input_shape=input_shape, return_sequences=True)))\n",
        "    model.add(Dropout(0.2))\n",
        "    # Layer 2\n",
        "    model.add(Bidirectional(LSTM(240, return_sequences=True)))\n",
        "    model.add(Dropout(0.2))\n",
        "    # Layer 3\n",
        "    model.add(Bidirectional(LSTM(240, return_sequences=True)))\n",
        "    # Layer 4\n",
        "    model.add(Bidirectional(LSTM(240, return_sequences=False)))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # Output Layers\n",
        "    model.add(Dense(49))              # Intermediate Dense\n",
        "    model.add(Dense(input_shape[1]))   # Final Output (7 numbers: 6 + Super)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss=\"mse\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "def run_lotto_logic(ui):\n",
        "    btn, txt, log_out, bar = ui['btn'], ui['txt'], ui['log'], ui['bar']\n",
        "\n",
        "    btn.disabled = True\n",
        "    bar.value = 0\n",
        "    log_out.clear_output()\n",
        "\n",
        "    def log(m):\n",
        "        with log_out: print(f\"[{time.strftime('%H:%M:%S')}] {m}\")\n",
        "\n",
        "    uid = txt.value.strip()\n",
        "    if not uid:\n",
        "        log(\"‚ùå FEHLER: Keine User ID!\"); btn.disabled = False; return\n",
        "\n",
        "    try:\n",
        "        log(f\"üöÄ Starte Heavy Analyse f√ºr: {uid}\")\n",
        "        bar.value = 5\n",
        "\n",
        "        # 1. Daten laden\n",
        "        log(\"üì• Lade 10 Jahre Archivdaten...\")\n",
        "        r = requests.get(\"https://www.lotto-bayern.de/static/gamebroker_2/de/download_files/archiv_lotto.zip\", timeout=30)\n",
        "        with zipfile.ZipFile(io.BytesIO(r.content)) as z: z.extractall(\"/content/lotto_temp\")\n",
        "\n",
        "        rows=[]\n",
        "        with open(\"/content/lotto_temp/lotto.txt\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            for l in f.readlines()[1:]:\n",
        "                p = l.split()\n",
        "                if len(p)>10 and int(p[2])>=2013: rows.append(p[3:10])\n",
        "\n",
        "        df = pd.DataFrame(rows).apply(pd.to_numeric, errors='coerce').dropna()\n",
        "        vals = df.values; vals[:,:6] = np.sort(vals[:,:6], axis=1) # Sort 6 main numbers\n",
        "\n",
        "        # 2. Preprocessing\n",
        "        bar.value = 15\n",
        "        log(\"‚öôÔ∏è Preprocessing & Windowing (Win=24)...\")\n",
        "\n",
        "        scaler = StandardScaler().fit(vals)\n",
        "        scaled = scaler.transform(vals)\n",
        "        win = 24\n",
        "        X = np.array([scaled[i:i+win] for i in range(len(scaled)-win)])\n",
        "        y = np.array([scaled[i+win] for i in range(len(scaled)-win)])\n",
        "\n",
        "        # 3. Model Build\n",
        "        log(\"üèóÔ∏è Baue Deep Learning Architektur (4x Bidirectional LSTM)...\")\n",
        "        input_shape = (win, 7)\n",
        "        model = create_model(input_shape)\n",
        "\n",
        "        # 4. Training (Heavy)\n",
        "        EPOCHS = 123\n",
        "        BATCH = 98\n",
        "\n",
        "        class P(Callback):\n",
        "            def on_epoch_end(s,e,l):\n",
        "                pct = int(20 + 75 * ((e+1)/EPOCHS))\n",
        "                bar.value = pct\n",
        "                if e % 20 == 0: log(f\"   Epoch {e+1}/{EPOCHS} loss={l['loss']:.4f}\")\n",
        "\n",
        "        log(f\"üß† Starte Training ({EPOCHS} Epochen)... Geduld bitte.\")\n",
        "        model.fit(X, y, epochs=EPOCHS, batch_size=BATCH, verbose=0, callbacks=[P()])\n",
        "\n",
        "        # 5. Prognose\n",
        "        log(\"üîÆ Berechne Vorhersage...\")\n",
        "        last_window = scaled[-win:].reshape(1, win, 7)\n",
        "        pred_scaled = model.predict(last_window)\n",
        "        pred = scaler.inverse_transform(pred_scaled)[0]\n",
        "\n",
        "        # Post-Processing (Runden & Bounds)\n",
        "        nums = [int(round(x)) for x in pred[:6]]\n",
        "        nums = sorted([min(49, max(1, x)) for x in nums]) # 1-49\n",
        "        sz = min(9, max(0, int(round(pred[6]))))   # 0-9\n",
        "\n",
        "        log(f\"‚úÖ ERGEBNIS: {nums} [Super: {sz}]\")\n",
        "        bar.value = 98\n",
        "\n",
        "        # 6. Senden\n",
        "        log(f\"üì° Upload zu App...\")\n",
        "        final_nums = nums\n",
        "\n",
        "        payload = {\n",
        "            \"userId\": uid,\n",
        "            \"numbers\": final_nums,\n",
        "            \"generated_at\": int(time.time()),\n",
        "            \"model\": \"LSTM-Deep-v1\"\n",
        "        }\n",
        "        res = requests.post(f\"{BACKEND}/api/colab/update\", json=payload)\n",
        "\n",
        "        if res.ok:\n",
        "            log(\"üéâ ERFOLG! Deine Zahlen sind in der App.\")\n",
        "            bar.value = 100\n",
        "        else:\n",
        "            log(f\"‚ö†Ô∏è Server Fehler: {res.status_code}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        log(f\"üí• CRITICAL ERROR: {e}\")\n",
        "\n",
        "    btn.disabled = False"
      ],
      "metadata": {
        "id": "13cKG6umi1yG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}